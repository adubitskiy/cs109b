{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 3: Traditional statistical and machine learning methods, due Wednesday, April 19, 2017\n",
    "\n",
    "Think about how you would address the genre prediction problem with traditional statistical or machine learning methods. This includes everything you learned about modeling in this course before the deep learning part. Implement your ideas and compare different classifiers. Report your results and discuss what challenges you faced and how you overcame them. What works and what does not? If there are parts that do not work as expected, make sure to discuss briefly what you think is the cause and how you would address this if you would have more time and resources. \n",
    "\n",
    "You do not necessarily need to use the movie posters for this step, but even without a background in computer vision, there are very simple features you can extract from the posters to help guide a traditional machine learning model. Think about the PCA lecture for example, or how to use clustering to extract color information. In addition to considering the movie posters it would be worthwhile to have a look at the metadata that IMDb provides. \n",
    "\n",
    "You could use Spark and the [ML library](https://spark.apache.org/docs/latest/ml-features.html#word2vec) to build your model features from the data. This may be especially beneficial if you use additional data, e.g., in text form.\n",
    "\n",
    "You also need to think about how you are going to evaluate your classifier. Which metrics or scores will you report to show how good the performance is?\n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Detailed description and implementation of two different models\n",
    "- Description of your performance metrics\n",
    "- Careful performance evaluations for both models\n",
    "- Visualizations of the metrics for performance evaluation\n",
    "- Discussion of the differences between the models, their strengths, weaknesses, etc. \n",
    "- Discussion of the performances you achieved, and how you might be able to improve them in the future\n",
    "\n",
    "#### Preliminary Peer Assessment\n",
    "\n",
    "It is important to provide positive feedback to people who truly worked hard for the good of the team and to also make suggestions to those you perceived not to be working as effectively on team tasks. We ask you to provide an honest assessment of the contributions of the members of your team, including yourself. The feedback you provide should reflect your judgment of each team member’s:\n",
    "\n",
    "- Preparation – were they prepared during team meetings?\n",
    "- Contribution – did they contribute productively to the team discussion and work?\n",
    "- Respect for others’ ideas – did they encourage others to contribute their ideas?\n",
    "- Flexibility – were they flexible when disagreements occurred?\n",
    "\n",
    "Your teammate’s assessment of your contributions and the accuracy of your self-assessment will be considered as part of your overall project score.\n",
    "\n",
    "Preliminary Peer Assessment: [https://goo.gl/forms/WOYC7pwRCSU0yV3l1](https://goo.gl/forms/WOYC7pwRCSU0yV3l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load: 2.1 secs\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_movie_df():\n",
    "    start = time.time()\n",
    "    with open(r\"../data/tmdb_df_5k.pickle\", \"rb\") as input_file:\n",
    "        movie_df = cPickle.load(input_file)\n",
    "    elapsed = time.time() - start\n",
    "    print \"load: %.1f secs\" % elapsed\n",
    "    return movie_df\n",
    "\n",
    "\n",
    "movie_df = load_movie_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "(5000, 1492)\n",
      "5000\n",
      "(5000, 2553)\n",
      "before scaling:\n",
      "before pca\n",
      "(3750L, 1058L)\n",
      "(1250L, 1058L)\n",
      "y_train shape:\n",
      "(3750, 20)\n",
      "(1250, 20)\n",
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,\n",
      "         1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
      "         1.00000e+02,   1.00000e+03])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=<function f1_score_f at 0x000000001A147668>, verbose=1)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0}\n",
      "train: 0.432, test: 0.120 (genre_TV Movie)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "train: 0.494, test: 0.177 (genre_Mystery)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "train: 0.504, test: 0.163 (genre_Fantasy)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "train: 0.134, test: 0.128 (genre_Family)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0000000000000001e-05}\n",
      "train: 0.511, test: 0.168 (genre_Horror)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "train: 0.145, test: 0.119 (genre_Crime)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "train: 0.298, test: 0.142 (genre_Adventure)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "train: 0.253, test: 0.193 (genre_Music)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "train: 0.299, test: 0.068 (genre_History)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0000000000000001e-05}\n",
      "train: 0.369, test: 0.179 (genre_Thriller)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "train: 0.283, test: 0.188 (genre_Romance)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.10000000000000001}\n",
      "train: 0.480, test: 0.098 (genre_Science Fiction)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "train: 0.633, test: 0.462 (genre_Drama)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100.0}\n",
      "train: 0.667, test: 0.411 (genre_Western)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.10000000000000001}\n",
      "train: 0.416, test: 0.140 (genre_Foreign)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 9.9999999999999995e-07}\n",
      "train: 0.494, test: 0.377 (genre_Comedy)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.10000000000000001}\n",
      "train: 0.579, test: 0.346 (genre_Action)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0}\n",
      "train: 0.120, test: 0.134 (genre_Animation)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "train: 0.419, test: 0.380 (genre_Documentary)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "{'alpha': 1.0}\n",
      "train: 0.366, test: 0.126 (genre_War)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.46      0.43        94\n",
      "          1       0.40      0.66      0.49       129\n",
      "          2       0.44      0.60      0.50       151\n",
      "          3       0.07      1.00      0.13       228\n",
      "          4       0.53      0.49      0.51       333\n",
      "          5       0.08      1.00      0.15       243\n",
      "          6       0.19      0.68      0.30       208\n",
      "          7       0.15      0.94      0.25       290\n",
      "          8       0.20      0.61      0.30        92\n",
      "          9       0.23      0.87      0.37       359\n",
      "         10       0.17      0.97      0.28       399\n",
      "         11       0.38      0.66      0.48       157\n",
      "         12       0.74      0.56      0.63      1367\n",
      "         13       0.59      0.77      0.67        94\n",
      "         14       0.33      0.55      0.42       123\n",
      "         15       0.35      0.83      0.49       920\n",
      "         16       0.54      0.63      0.58       411\n",
      "         17       0.06      1.00      0.12       239\n",
      "         18       0.27      0.92      0.42       520\n",
      "         19       0.25      0.71      0.37        84\n",
      "\n",
      "avg / total       0.39      0.75      0.44      6441\n",
      "\n",
      "test\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.11      0.13      0.12        23\n",
      "          1       0.13      0.29      0.18        45\n",
      "          2       0.13      0.22      0.16        50\n",
      "          3       0.07      0.94      0.13        80\n",
      "          4       0.17      0.17      0.17       105\n",
      "          5       0.06      0.82      0.12        84\n",
      "          6       0.09      0.36      0.14        76\n",
      "          7       0.11      0.86      0.19        91\n",
      "          8       0.05      0.12      0.07        41\n",
      "          9       0.11      0.56      0.18        99\n",
      "         10       0.11      0.71      0.19       136\n",
      "         11       0.07      0.15      0.10        48\n",
      "         12       0.56      0.39      0.46       451\n",
      "         13       0.31      0.60      0.41        25\n",
      "         14       0.11      0.20      0.14        40\n",
      "         15       0.26      0.66      0.38       316\n",
      "         16       0.29      0.43      0.35       117\n",
      "         17       0.07      1.00      0.13        90\n",
      "         18       0.24      0.85      0.38       183\n",
      "         19       0.08      0.25      0.13        28\n",
      "\n",
      "avg / total       0.25      0.55      0.28      2128\n",
      "\n",
      "train: 0.395, test: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "def get_reduced_movie_df(movie_df):\n",
    "    movie_attribute_name_list = [\n",
    "        'popularity',\n",
    "        'revenue',\n",
    "        'budget',\n",
    "        'vote_count',\n",
    "        'vote_average',\n",
    "        'cast',\n",
    "        'crew',\n",
    "\n",
    "        'genres',\n",
    "    ]\n",
    "    return movie_df[movie_attribute_name_list]\n",
    "\n",
    "\n",
    "def prepare_genre_columns(movie_df):\n",
    "    num_movies = len(movie_df)\n",
    "    genre_df_dict = defaultdict(lambda: np.zeros((num_movies,), dtype=np.uint8))\n",
    "\n",
    "    for i, genre_list in enumerate(movie_df['genres']):\n",
    "        for genre in genre_list:\n",
    "            genre_name = genre['name']\n",
    "            genre_df_dict['genre_' + genre_name][i] = 1\n",
    "\n",
    "    new_movie_df = movie_df.drop(\"genres\", axis=1)\n",
    "\n",
    "    for key, column in genre_df_dict.iteritems():\n",
    "        new_movie_df[key] = column\n",
    "\n",
    "    return new_movie_df\n",
    "\n",
    "\n",
    "def prepare_cast(movie_df, genre_name):\n",
    "    cast_list = [cast_member['name'] for movie_cast_list in movie_df[genre_name] for cast_member in movie_cast_list]\n",
    "    cast_counter = Counter(cast_list)\n",
    "\n",
    "    appearances_limit = 3\n",
    "    included_cast_list = [cast_name for cast_name, num_movies in cast_counter.iteritems()\n",
    "                          if num_movies >= appearances_limit]\n",
    "    included_cast_set = set(included_cast_list)\n",
    "\n",
    "    num_movies = len(movie_df)\n",
    "    print num_movies\n",
    "    movie_attribute_dict = defaultdict(lambda: np.zeros((num_movies,), dtype=np.uint8))\n",
    "\n",
    "    for i, movie_cast_list in enumerate(movie_df[genre_name]):\n",
    "        for cast_member in movie_cast_list:\n",
    "            cast_name = cast_member['name']\n",
    "            if cast_name in included_cast_set:\n",
    "                movie_attribute_dict[genre_name + '_' + cast_name][i] = 1\n",
    "\n",
    "    new_movie_df = movie_df.drop(genre_name, axis=1)\n",
    "\n",
    "    for key, column in movie_attribute_dict.iteritems():\n",
    "        new_movie_df[key] = column\n",
    "\n",
    "    print new_movie_df.shape\n",
    "    return new_movie_df\n",
    "\n",
    "\n",
    "def apply_pca(X_train, X_test):\n",
    "    print \"before scaling:\"\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "    print \"before pca\"\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train_scaled)\n",
    "\n",
    "    cutoff_index = np.argmin(np.cumsum(pca.explained_variance_ratio_) <= 0.9)\n",
    "\n",
    "    pca_X_train = pca.transform(X_train_scaled)\n",
    "    pca_X_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    pca_X_train = pca_X_train[:, :cutoff_index]\n",
    "    pca_X_test = pca_X_test[:, :cutoff_index]\n",
    "\n",
    "    print pca_X_train.shape\n",
    "    print pca_X_test.shape\n",
    "\n",
    "    return pca_X_train, pca_X_test\n",
    "\n",
    "\n",
    "def prepare_movie_df(movie_df):\n",
    "    reduced_movie_df = get_reduced_movie_df(movie_df)\n",
    "    reduced_movie_df = prepare_genre_columns(reduced_movie_df)\n",
    "    reduced_movie_df = prepare_cast(reduced_movie_df, 'cast')\n",
    "    reduced_movie_df = prepare_cast(reduced_movie_df, 'crew')\n",
    "\n",
    "    return reduced_movie_df\n",
    "\n",
    "\n",
    "def default_score(classifier, X, y):\n",
    "    y_pred = classifier.predict(X)\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "def f1_score_f(classifier, X, y):\n",
    "    y_pred = classifier.predict(X)\n",
    "    return f1_score(y, y_pred)\n",
    "\n",
    "\n",
    "def run_model_with_y_matrix(train_df, test_df, classifier, score_f):\n",
    "    X_columns = [column for column in train_df.columns if not column.startswith('genre_')]\n",
    "    y_columns = [column for column in train_df.columns if column.startswith('genre_')]\n",
    "\n",
    "    X_train = train_df[X_columns]\n",
    "    X_test = test_df[X_columns]\n",
    "\n",
    "    X_train, X_test = apply_pca(X_train, X_test)\n",
    "\n",
    "    y_train = train_df[y_columns]\n",
    "    y_test = test_df[y_columns]\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    train_score = score_f(classifier, X_train, y_train)\n",
    "    test_score = score_f(classifier, X_test, y_test)\n",
    "\n",
    "    # print classifier.best_params_\n",
    "    print \"train: %.3f, test: %.3f\" % (train_score, test_score)\n",
    "\n",
    "\n",
    "def run_model(train_df, test_df, classifier, score_f):\n",
    "    X_columns = [column for column in train_df.columns if not column.startswith('genre_')]\n",
    "    y_columns = [column for column in train_df.columns if column.startswith('genre_')]\n",
    "\n",
    "    X_train = train_df[X_columns]\n",
    "    X_test = test_df[X_columns]\n",
    "\n",
    "    X_train, X_test = apply_pca(X_train, X_test)\n",
    "\n",
    "    y_train = train_df[y_columns]\n",
    "    y_test = test_df[y_columns]\n",
    "\n",
    "    print 'y_train shape:'\n",
    "    print y_train.shape\n",
    "    print y_test.shape\n",
    "\n",
    "    train_score_list = []\n",
    "    test_score_list = []\n",
    "\n",
    "    print classifier\n",
    "\n",
    "    y_train_pred_list = []\n",
    "    y_test_pred_list = []\n",
    "\n",
    "    for y_column in y_columns:\n",
    "        y_train_col = train_df[y_column]\n",
    "        y_test_col = test_df[y_column]\n",
    "\n",
    "        train_score, test_score, y_train_pred, y_test_pred = run_model_one_y(y_column, X_train, X_test, y_train_col,\n",
    "                                                                             y_test_col, classifier, score_f)\n",
    "\n",
    "        train_score_list.append(train_score)\n",
    "        test_score_list.append(test_score)\n",
    "\n",
    "        y_train_pred_list.append(y_train_pred)\n",
    "        y_test_pred_list.append(y_test_pred)\n",
    "\n",
    "    y_train_pred_result = np.array(y_train_pred_list).T\n",
    "    y_test_pred_result = np.array(y_test_pred_list).T\n",
    "\n",
    "    print classification_report(y_train, y_train_pred_result)\n",
    "    print 'test'\n",
    "    print classification_report(y_test, y_test_pred_result)\n",
    "\n",
    "    print \"train: %.3f, test: %.3f\" % (np.mean(train_score_list), np.mean(test_score_list))\n",
    "\n",
    "\n",
    "def run_model_one_y(genre, X_train, X_test, y_train, y_test, classifier, score_f):\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    train_score = score_f(classifier, X_train, y_train)\n",
    "    test_score = score_f(classifier, X_test, y_test)\n",
    "\n",
    "    print classifier.best_params_\n",
    "    print \"train: %.3f, test: %.3f (%s)\" % (train_score, test_score, genre)\n",
    "\n",
    "    return train_score, test_score, classifier.predict(X_train), classifier.predict(X_test)\n",
    "\n",
    "\n",
    "reduced_movie_df = prepare_movie_df(movie_df)\n",
    "train_df, test_df = train_test_split(reduced_movie_df, random_state=109)\n",
    "\n",
    "# run_model(train_df, test_df, classifier=DummyClassifier(strategy=\"most_frequent\"), score_f=default_score)\n",
    "\n",
    "# run_model_2(train_df, test_df, classifier=DummyClassifier(strategy=\"most_frequent\"), score_f=f1_score_f)\n",
    "# run_model_2(train_df, test_df, classifier=DummyClassifier(strategy=\"stratified\"), score_f=f1_score_f)\n",
    "# run_model_2(train_df, test_df, classifier=DummyClassifier(strategy=\"uniform\"), score_f=f1_score_f)\n",
    "\n",
    "# run_model_2(train_df, test_df, classifier=DummyClassifier(strategy=\"most_frequent\"), score_f=default_score)\n",
    "# run_model_2(train_df, test_df, classifier=DummyClassifier(strategy=\"stratified\"), score_f=default_score)\n",
    "# run_model_2(train_df, test_df, classifier=DummyClassifier(strategy=\"uniform\"), score_f=default_score)\n",
    "\n",
    "# run_model(train_df, test_df, classifier=SVC(class_weight='balanced', kernel='linear'), score_f=f1_score_f)\n",
    "\n",
    "estimator = GridSearchCV(\n",
    "    estimator=SGDClassifier(class_weight='balanced'),\n",
    "    param_grid={\n",
    "        'alpha': np.logspace(-6, 3, num=10),\n",
    "    },\n",
    "    scoring=f1_score_f,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# estimator = SGDClassifier(class_weight='balanced', alpha=10 ** -2)\n",
    "\n",
    "# run_model_2(train_df, test_df, classifier=estimator, score_f=default_score)\n",
    "run_model(train_df, test_df, classifier=estimator, score_f=f1_score_f)\n",
    "\n",
    "# run_model(train_df, test_df, classifier=SVC(class_weight='balanced', kernel='linear'), score_f=f1_score_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}