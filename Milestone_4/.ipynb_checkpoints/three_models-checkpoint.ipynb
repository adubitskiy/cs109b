{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import applications, optimizers\n",
    "from keras import backend as K\n",
    "from keras.engine import Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Conv2D, Activation, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "nb_train_samples = 1536\n",
    "nb_validation_samples = 512\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained model + fully-connected block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 4 classes.\n",
      "3/3 [==============================] - 42s     \n",
      "Found 32 images belonging to 4 classes.\n",
      "1/1 [==============================] - 12s\n"
     ]
    }
   ],
   "source": [
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        train_generator,\n",
    "        steps=nb_train_samples // batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('train_classes.npy', 'wb'), train_generator.classes)\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        validation_generator,\n",
    "        steps=nb_validation_samples // batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "    np.save(open('validation_classes.npy', 'wb'), validation_generator.classes)\n",
    "\n",
    "    \n",
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Train on 96 samples, validate on 32 samples\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 0s - loss: 8.6367 - acc: 0.1875 - val_loss: 8.2249 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s - loss: 9.3093 - acc: 0.3125 - val_loss: 5.0686 - val_acc: 0.3438\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s - loss: 11.5381 - acc: 0.1667 - val_loss: 7.5938 - val_acc: 0.2500\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s - loss: 10.3545 - acc: 0.2917 - val_loss: 2.9115 - val_acc: 0.3750\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s - loss: 10.8783 - acc: 0.2292 - val_loss: 3.4692 - val_acc: 0.3438\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s - loss: 10.0125 - acc: 0.2604 - val_loss: 7.1161 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s - loss: 9.9877 - acc: 0.2917 - val_loss: 7.3156 - val_acc: 0.2500\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s - loss: 11.8678 - acc: 0.2188 - val_loss: 8.3434 - val_acc: 0.2500\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s - loss: 10.6600 - acc: 0.2604 - val_loss: 7.4796 - val_acc: 0.2500\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s - loss: 10.5481 - acc: 0.2708 - val_loss: 6.4970 - val_acc: 0.3438\n",
      "32/32 [==============================] - 0s\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[3 3 2 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 2 3 3 3 3 2\n",
      " 3 3 3 3 3 3 3 2 3 3 3 2 2 2 2 2 2 3 2 2 3 3 2 2 2 2 2 3 3 3 3 3 3 2 2 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        24\n",
      "          1       0.00      0.00      0.00        24\n",
      "          2       0.68      0.62      0.65        24\n",
      "          3       0.31      0.96      0.47        24\n",
      "\n",
      "avg / total       0.25      0.40      0.28        96\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3]\n",
      "[3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 3 3 2 2 3 3 2 3 3 3 3 3 3 3]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         8\n",
      "          1       0.00      0.00      0.00         8\n",
      "          2       0.57      0.50      0.53         8\n",
      "          3       0.28      0.88      0.42         8\n",
      "\n",
      "avg / total       0.21      0.34      0.24        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timur\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def print_report(train_classes, validation_classes, y_train_pred, y_validation_pred):\n",
    "    print(train_classes)\n",
    "    print(y_train_pred)\n",
    "    print(classification_report(train_classes, y_train_pred))\n",
    "    print(validation_classes)\n",
    "    print(y_validation_pred)\n",
    "    print(classification_report(validation_classes, y_validation_pred))\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "    train_classes = np.load(open('train_classes.npy', 'rb'))\n",
    "    num_classes = len(np.unique(train_classes))\n",
    "    print(num_classes)\n",
    "    train_labels = to_categorical(train_classes)\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "    validation_classes = np.load(open('validation_classes.npy', 'rb'))\n",
    "    validation_labels = to_categorical(validation_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_data, train_labels,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_data, validation_labels),\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    y_train_pred = model.predict_classes(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    y_validation_pred = model.predict_classes(\n",
    "        validation_data,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print_report(train_classes, validation_classes, y_train_pred, y_validation_pred)\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from scratch (a small convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Found 96 images belonging to 4 classes.\n",
      "Found 32 images belonging to 4 classes.\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 6s - loss: 5.1212 - acc: 0.2917 - val_loss: 1.5349 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 5s - loss: 1.4608 - acc: 0.3333 - val_loss: 1.3775 - val_acc: 0.2500\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 5s - loss: 1.3773 - acc: 0.2812 - val_loss: 1.3658 - val_acc: 0.2500\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 5s - loss: 1.3857 - acc: 0.2500 - val_loss: 1.3618 - val_acc: 0.2500\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 5s - loss: 1.3588 - acc: 0.3229 - val_loss: 1.3614 - val_acc: 0.2500\n",
      "3/3 [==============================] - 1s     \n",
      "1/1 [==============================] - 0s\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.92      0.39        24\n",
      "          1       0.00      0.00      0.00        24\n",
      "          2       0.00      0.00      0.00        24\n",
      "          3       0.50      0.08      0.14        24\n",
      "\n",
      "avg / total       0.19      0.25      0.13        96\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.26      1.00      0.41         8\n",
      "          1       0.00      0.00      0.00         8\n",
      "          2       0.00      0.00      0.00         8\n",
      "          3       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.06      0.25      0.10        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timur\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def generator_print_report(model, train_classes, train_generator, validation_classes, validation_generator):\n",
    "    y_train_proba = model.predict_generator(\n",
    "        train_generator,\n",
    "        steps=nb_train_samples // batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "    y_train_pred = [np.argmax(y) for y in y_train_proba]\n",
    "    y_validation_proba = model.predict_generator(\n",
    "        validation_generator,\n",
    "        steps=nb_validation_samples // batch_size,\n",
    "        verbose=1,\n",
    "    )\n",
    "    y_validation_pred = [np.argmax(y) for y in y_validation_proba]\n",
    "    print_report(train_classes, validation_classes, y_train_pred, y_validation_pred)\n",
    "\n",
    "\n",
    "def small_conv_net_from_scratch():\n",
    "    train_classes = np.load(open('train_classes.npy', 'rb'))\n",
    "    num_classes = len(np.unique(train_classes))\n",
    "    print(num_classes)\n",
    "\n",
    "    validation_classes = np.load(open('validation_classes.npy', 'rb'))\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "    )\n",
    "\n",
    "    generator_print_report(model, train_classes, train_generator, validation_classes, validation_generator)\n",
    "\n",
    "    model.save_weights('first_try.h5')\n",
    "\n",
    "    \n",
    "small_conv_net_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained model (vgg16) + conv block + fully-connected block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "4\n",
      "Found 96 images belonging to 4 classes.\n",
      "Found 32 images belonging to 4 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 4)                 6439492   \n",
      "=================================================================\n",
      "Total params: 21,154,180\n",
      "Trainable params: 13,518,916\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "53s - loss: 10.9089 - acc: 0.2188 - val_loss: 6.2491 - val_acc: 0.2812\n",
      "3/3 [==============================] - 32s     \n",
      "1/1 [==============================] - 10s\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        24\n",
      "          1       0.00      0.00      0.00        24\n",
      "          2       0.41      0.29      0.34        24\n",
      "          3       0.25      0.83      0.39        24\n",
      "\n",
      "avg / total       0.17      0.28      0.18        96\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3]\n",
      "[3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         8\n",
      "          1       0.00      0.00      0.00         8\n",
      "          2       0.33      0.38      0.35         8\n",
      "          3       0.30      0.88      0.45         8\n",
      "\n",
      "avg / total       0.16      0.31      0.20        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timur\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_convolution_block():\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "    print('Model loaded.')\n",
    "\n",
    "    train_classes = np.load(open('train_classes.npy', 'rb'))\n",
    "    num_classes = len(np.unique(train_classes))\n",
    "    print(num_classes)\n",
    "\n",
    "    validation_classes = np.load(open('validation_classes.npy', 'rb'))\n",
    "\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.75))\n",
    "    top_model.add(Dense(64, activation='relu'))\n",
    "    top_model.add(Dropout(0.75))\n",
    "    top_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    generator_print_report(model, train_classes, train_generator, validation_classes, validation_generator)\n",
    "\n",
    "    \n",
    "fine_tune_convolution_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
