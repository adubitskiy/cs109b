{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Keenan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV as gsearch\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier as forest\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.cross_validation import KFold\n",
    "import nltk.data\n",
    "%matplotlib inline\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pic.dump(obj, f, pic.HIGHEST_PROTOCOL)\n",
    "def load_obj(name ):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pic.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_k = load_obj('data/tmdb_df_5k.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_overview_clean(df):\n",
    "    ret_df = df.copy()\n",
    "    return ret_df[['title', 'genres', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_k_over = df_overview_clean(five_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary',\n",
    "           'Drama', 'Family', 'Fantasy', 'Foreign', 'History', 'Horror', 'Music',\n",
    "            'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genre_extract(genre_dic):\n",
    "    ret_genres = []\n",
    "    for dic in genre_dic:\n",
    "        ret_genres.append(dic['name'])\n",
    "    return ret_genres\n",
    "\n",
    "def assign_genre_vector(row_genres, all_classes):\n",
    "    ret_list = []\n",
    "    genre_list = genre_extract(row_genres)\n",
    "    for genre in all_classes:\n",
    "        if genre in genre_list:\n",
    "            ret_list.append(1)\n",
    "        else:\n",
    "            ret_list.append(0)\n",
    "    return ret_list           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_k_vec = pd.DataFrame(columns=['title', 'genres', 'overview', 'genre_vec', 'all_genres'])\n",
    "for row in zip(five_k_over['title'], five_k_over['genres'], five_k_over['overview']):\n",
    "    genre_vec = assign_genre_vector(row[1], classes)\n",
    "    genres = genre_extract(row[1])\n",
    "    \n",
    "    #had to throw this in for the vectorization process-later\n",
    "    overview = row[2]\n",
    "    if row[2] == None or not row[2]:\n",
    "        overview = 'a'\n",
    "    five_k_vec = five_k_vec.append({'title':row[0], 'genres':row[1], 'overview':overview, 'genre_vec':genre_vec, 'all_genres':genres}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set our vectorization\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words(\"english\"),\n",
    "    max_df = 0.9, \n",
    "    min_df = 5, \n",
    "    dtype=np.float32 )\n",
    "\n",
    "corpus = five_k_vec['overview'].values\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "ys = MultiLabelBinarizer().fit_transform(five_k_vec['all_genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/36523558/multi-class-logistic-regression-in-scikit-learn\n",
    "#And you seem to be looking for multilabel (as for multiclass labels should be 1-dim). \n",
    "#Currently, in sklearn, the only methods supporting multilabel are:\n",
    "#Decision Trees, Random Forests, Nearest Neighbors, Ridge Regression.\n",
    "#have to use onevsrest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val_mod(X_train, y_train, mod, parameters, folds = 5):\n",
    "    grid_clf = gsearch(mod, parameters, cv=folds)\n",
    "    grid_clf.fit(X_train, y_train)\n",
    "    return (grid_clf.best_estimator_, grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16266666666666665"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log Reg without CV\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,ys,test_size=0.3)\n",
    "\n",
    "oneVsResClassifier = OneVsRestClassifier(LogReg()).fit(X_train, y_train)\n",
    "\n",
    "oneVsResClassifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14799999999999999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forest without CV\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,ys,test_size=0.3)\n",
    "\n",
    "forest_mod = forest()\n",
    "forest_mod.fit(X_train, y_train)\n",
    "\n",
    "forest_mod.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These only perform as well as the baseline, probably because they are over classifying the most popular classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00866666666667\n",
      "{'n_estimators': 5, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "#forest with CV\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,ys,test_size=0.3)\n",
    "\n",
    "params = {'n_estimators': [5, 10, 15, 20],\n",
    "          'max_depth': [2, 5, 7, 9]}\n",
    "cv_mod = cross_val_mod(X_train, y_train, forest(), params, 10)\n",
    "\n",
    "print cv_mod[0].score(X_test, y_test)\n",
    "print cv_mod[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.146\n",
      "{'estimator__C': 0.10000000000000001}\n"
     ]
    }
   ],
   "source": [
    "#Log Reg with CV\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,ys,test_size=0.3)\n",
    "\n",
    "all_c = np.power(10.0, range(-3, 3))\n",
    "\n",
    "params = {'estimator__C':all_c}\n",
    "\n",
    "cv_mod = cross_val_mod(X_train, y_train, OneVsRestClassifier(LogReg(class_weight='balanced')), params, 5)\n",
    "\n",
    "print cv_mod[0].score(X_test, y_test)\n",
    "print cv_mod[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
