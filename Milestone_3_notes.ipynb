{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Final Project - Predicting Movie Genres!\n",
    "\n",
    "![Movie genre header](genre_header.jpg)\n",
    "\n",
    "Welcome to the final project of CS109b. \n",
    "\n",
    "The overall theme of the final project is movie data with a focus on movie genre prediction, because it is an area where we all are more or less application domain experts. First, you will explore your data and the challenges of the problem by exploratory data analysis. Use visualizations to find features that correlate with movie genres. These can be extracted from the movie posters, or meta data, or other data you gather, for example plot summaries or even movie transcripts. You will then compare traditional statistical or machine learning methods like generalized additive models, random forest, Bayesian prediction methods, boosting, and SVM, to deep learning models for movie genre prediction. \n",
    "\n",
    "For this project you will work in teams of 3-4 people and there are weekly milestones to guide you along the way. Even though the milestones are graded, they are mainly in place to make sure you stay in contact with your TF and make progress with the project. Throughout the project you also have room for creativity and to pursue your own ideas. While you need to hand in the milestones at the appropriate due date, there is nothing preventing you from working on a later milestone ahead of time. We suggest that you read through the whole project and all milestones in the beginning to be able to plan ahead. The project is pretty open ended, so you can be creative and let your data science knowledge shine! \n",
    "\n",
    "For each milestone you will submit a notebook, in raw (`.ipynb`) and PDF formats, containing the deliverables of that week and the extra work you did so far. The notebooks need to contain your code, comments, explanations, thoughts, and visualizations. The final deliverables are a two-minute screencast, a report in paper style for a general data science audience, and all your data and code that you developed throughout the project. \n",
    "\n",
    "Below is a description of the data and the milestones with their due dates. All work is due by 11:59PM on the due date unless otherwise specified. We expect you to have the mandatory parts finished by the milestone due dates, and there will be no extensions. However, we strongly encourage you to plan ahead. For example, you need to think about the classification task early on to plan how you want to assemble your training data, and it is beneficial to start the deep learning work as early as possible. There is nothing hindering you to already train a model in the EDA phase to get a better feel for what challenges might lay ahead with the data. You should also see the milestone requirements as a basis for your own creativity, and we expect that most of you will go beyond the mandatory deliverables. For example, if you have a great idea about an interesting question that has to do with movie genre, but cannot be answered with the data from TMDb or IMDb, feel free to gather more data from somewhere else. \n",
    "\n",
    "We provide a data interface in Python, because it is convenient for IMDb, and we will use Python for the deep learning part. Specifically we will use Keras, a deep learning library that provides a high level interface to Google's Tensorflow framework for deep learning. However, if you feel that you prefer to do some of the work, e.g., visualizations or data cleanup, in R then feel free to use it. You can also use Spark to preprocess your data, especially if you collect large amounts of it from other sources. \n",
    "\n",
    "*Important:* Your grade for a milestone will depend on the required deliverables you submit at the due date for that milestone. But every milestone, especially the final project submission, can contain additional cool work you did that goes beyond the deliverables spelled out below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Logistics \n",
    "\n",
    "Please adhere to the following guidelines for all submissions:\n",
    "- one submission per team\n",
    "- notebooks should be submitted as PDF and as raw (`.ipynb`) version\n",
    "- all notebooks should be executed so they contain relevant visualizations, and other results\n",
    "- try to make it as easy as possible for the TFs to get all relevant information about your work\n",
    "- do not submit big data sets, please provide a readme file with a link instead\n",
    "- the final report should also be submitted as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Movie Data:\n",
    "\n",
    "The project is based on two different sources of movie data: [IMDb](http://www.imdb.com/) and [TMDb](https://www.themoviedb.org/). TMDb is great, because it provides the movie posters in addition to the metadata. This is crucial for the deep learning part, in which you will try to predict movie genres from posters. IMDb has more metadata available and will supplement the TMDb data you have. \n",
    "\n",
    "TMDb provides an easy to use [API](https://www.themoviedb.org/documentation/api) that allows you to download the data selectively. IMDb does not provide an API, but there is a Python interface available to access the metadata. We will use [IMDbPY](http://imdbpy.sourceforge.net/), which is already installed on the AMI and virtual box images for your convenience.\n",
    "\n",
    "*Important*: Please remember to limit your data rate when obtaining the data. Play nicely and do not just spam servers as fast as you can. This will prevent your IP from getting banned. The easiest way to do is is to use the [sleep](http://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python) function in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Milestone 3: Traditional statistical and machine learning methods, due Wednesday, April 19, 2017\n",
    "\n",
    "Think about how you would address the genre prediction problem with traditional statistical or machine learning methods. This includes everything you learned about modeling in this course before the deep learning part. Implement your ideas and compare different classifiers. Report your results and discuss what challenges you faced and how you overcame them. What works and what does not? If there are parts that do not work as expected, make sure to discuss briefly what you think is the cause and how you would address this if you would have more time and resources. \n",
    "\n",
    "You do not necessarily need to use the movie posters for this step, but even without a background in computer vision, there are very simple features you can extract from the posters to help guide a traditional machine learning model. Think about the PCA lecture for example, or how to use clustering to extract color information. In addition to considering the movie posters it would be worthwhile to have a look at the metadata that IMDb provides. \n",
    "\n",
    "You could use Spark and the [ML library](https://spark.apache.org/docs/latest/ml-features.html#word2vec) to build your model features from the data. This may be especially beneficial if you use additional data, e.g., in text form.\n",
    "\n",
    "You also need to think about how you are going to evaluate your classifier. Which metrics or scores will you report to show how good the performance is?\n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Detailed description and implementation of two different models\n",
    "- Description of your performance metrics\n",
    "- Careful performance evaluations for both models\n",
    "- Visualizations of the metrics for performance evaluation\n",
    "- Discussion of the differences between the models, their strengths, weaknesses, etc. \n",
    "- Discussion of the performances you achieved, and how you might be able to improve them in the future\n",
    "\n",
    "#### Preliminary Peer Assessment\n",
    "\n",
    "It is important to provide positive feedback to people who truly worked hard for the good of the team and to also make suggestions to those you perceived not to be working as effectively on team tasks. We ask you to provide an honest assessment of the contributions of the members of your team, including yourself. The feedback you provide should reflect your judgment of each team member’s:\n",
    "\n",
    "- Preparation – were they prepared during team meetings?\n",
    "- Contribution – did they contribute productively to the team discussion and work?\n",
    "- Respect for others’ ideas – did they encourage others to contribute their ideas?\n",
    "- Flexibility – were they flexible when disagreements occurred?\n",
    "\n",
    "Your teammate’s assessment of your contributions and the accuracy of your self-assessment will be considered as part of your overall project score.\n",
    "\n",
    "Preliminary Peer Assessment: [https://goo.gl/forms/WOYC7pwRCSU0yV3l1](https://goo.gl/forms/WOYC7pwRCSU0yV3l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone Call Notes\n",
    "\n",
    "Posters: Will be done by deep learning. We anticiapte medicore accuracy but should try.\n",
    "\n",
    "Textual Feature set: Director name, crew name, actors name\n",
    "Ensembles: A combination of models, possbibly a SVM and Random Forrest \n",
    "Textaul analysis: Linear Disrminant Analysis\n",
    "\n",
    "Try committing smaller subsets of the data to quickly test a model and compare accuracy.\n",
    "5k, 3k datasets to try on the full model.\n",
    "\n",
    "Models to try:\n",
    "SVM\n",
    "Multinomial logistic regression\n",
    "Random Forrest\n",
    "\n",
    "Selecting Feautre Set:\n",
    "\n",
    "Images-with genre\n",
    "\n",
    "Combine with everything-overview/plot, crew, director, actor (Try two different approaches, using these vectors as a text with a text analysis model (specifically on overview/plot), like LDA. Alterante option is to encode using binary for each observation). Possibly include ratings, revenue, budget, revenue after analyzing their contribution to the ratings as a model.\n",
    "\n",
    "Alternate Textual analysis: Using a data set of scripts, find the most important words used in prediction of geren after vectorizing all words in the scripts. Then run a logistic regression on the vectorized observations for each movie.\n",
    "\n",
    "Subsetting data:\n",
    "Plan on having 20k, 5k, 3k subset of data to test the two following models until they are fully produced. Once a final statistical learning methodology is chosen, we will run the model (after tuning parameters through cross validation).\n",
    "\n",
    "Model 1: - Keenan will focus on\n",
    "A textual analysis based on overview, plot, possibly script and alternate text information that describes the movie. From there, either seperate models are sets of features for each text source will be combined. Then test a Support Vector Machine LDA(or another model used in textual analysis in this class) or a logistic regression to see predictive power.\n",
    "\n",
    "Model 2:\n",
    "An analysis using crew, director, actor (transformed to features using binary encoding) coupled with our feature set including things like ratings, revenue, budget. From there we can determine the most important features based on a corrplot. With this feature heavy dataset, test SVM, LogReg and possibly a random forrest to see what works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed description and implementation of two different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of your performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Careful performance evaluations for both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations of the metrics for performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the differences between the models, their strengths, weaknesses, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the performances you achieved, and how you might be able to improve them in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
