{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 4: Deep learning, due Wednesday, April 26, 2017\n",
    "\n",
    "For this milestone you will (finally) use deep learning to predict movie genres. You will train one small network from scratch on the posters only, and compare this one to a pre-trained network that you finetune. [Here](https://keras.io/getting-started/faq/#how-can-i-use-pre-trained-models-in-keras) is a description of how to use pretrained models in Keras.\n",
    "\n",
    "You can try different architectures, initializations, parameter settings, optimization methods, etc. Be adventurous and explore deep learning! It can be fun to combine the features learned by the deep learning model with a SVM, or incorporate meta data into your deep learning model. \n",
    "\n",
    "**Note:** Be mindful of the longer training times for deep models. Not only for training time, but also for the parameter tuning efforts. You need time to develop a feel for the different parameters and which settings work, which normalization you want to use, which model architecture you choose, etc. \n",
    "\n",
    "It is great that we have GPU's via AWS to speed up the actual computation time, but you need to be mindful of your AWS credits. The GPU instances are not cheap and can accumulate costs rather quickly. Think about your model first and do some quick dry runs with a larger learning rate or large batch size on your local machine. \n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. \n",
    "- Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. \n",
    "- Discussion of the results, how much improvement you gained with fine tuning, etc. \n",
    "- Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 4 submission\n",
    "## Team 37 (Alexander Dubitskiy, Keenan Venuti, Timur Zambalayev)\n",
    "\n",
    "Github repo link: https://github.com/adubitskiy/cs109b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is the link for the notebook: https://github.com/adubitskiy/cs109b/blob/master/model_custom_loss.ipynb\n",
    "\n",
    "The data consisted of 58,825 movies. We reserved 10% for the test dataset (5,883 samples). The train set had 52,942 movies. \n",
    "During the fit we set aside 20% for validation (10,589 samples), so we trained on 42,353 samples.\n",
    "The image sizes: 224x224x3 (rgb).\n",
    "\n",
    "We used 4 convolution layers and 2 fully conected layers regularized by the dropouts.\n",
    "The loss function was weighted crossentropy. Batch size was 128.\n",
    "\n",
    "First we did rough tuning using Nesterov Adam optimizer (optimizer = 'nadam'). We used early stopping (stop when vaidation loss is not going down for 5 epochs). The rough tuning lasted for 17 epochs (each epoch taking around 200 seconds).\n",
    "The train loss went from 29.2 to 8.9. The validation loss - from 26.9 to 21.6.\n",
    "\n",
    "After that it was more precise tuning with a small step size (optimizer=SGD(lr = 0.0001, momentum=0.9)).\n",
    "That took 7 additional epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the results, how much improvement you gained with fine tuning, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
